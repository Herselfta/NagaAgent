# æ ‡å‡†åº“å¯¼å…¥
import asyncio
import json
import logging
import os
import re
import sys
import time
import traceback
from datetime import datetime
from typing import List, Dict

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
from openai import AsyncOpenAI
import google.generativeai as genai

# æœ¬åœ°æ¨¡å—å¯¼å…¥
from apiserver.tool_call_utils import parse_tool_calls, execute_tool_calls, tool_call_loop
from config import config
from mcpserver.mcp_manager import get_mcp_manager
from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX
# from thinking import TreeThinkingEngine
from thinking.config import COMPLEX_KEYWORDS

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
def setup_logging():
    """ç»Ÿä¸€é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_level = getattr(logging, config.system.log_level.upper(), logging.INFO)
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler(sys.stderr)]
    )
    
    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    for logger_name in ["httpcore.connection", "httpcore.http11", "httpx", "openai._base_client", "asyncio"]:
        logging.getLogger(logger_name).setLevel(logging.WARNING)

setup_logging()
logger = logging.getLogger("NagaConversation")

# å…¨å±€çŠ¶æ€ç®¡ç†
class SystemState:
    """ç³»ç»ŸçŠ¶æ€ç®¡ç†å™¨"""
    _tree_thinking_initialized = False
    _mcp_services_initialized = False
    _voice_enabled_logged = False
    _memory_initialized = False

# GRAGè®°å¿†ç³»ç»Ÿå¯¼å…¥
def init_memory_manager():
    """åˆå§‹åŒ–GRAGè®°å¿†ç³»ç»Ÿ"""
    if not config.grag.enabled:
        return None
    
    try:
        from summer_memory.memory_manager import memory_manager
        print("[GRAG] âœ… å¤å›­è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        return memory_manager
    except Exception as e:
        logger.error(f"å¤å›­è®°å¿†ç³»ç»ŸåŠ è½½å¤±è´¥: {e}")
        return None

memory_manager = init_memory_manager()

# è¯­éŸ³ç³»ç»Ÿå¯¼å…¥
def init_voice_system():
    """æ ¹æ®é…ç½®åˆå§‹åŒ–è¯­éŸ³ç³»ç»Ÿ"""
    if not config.system.voice_enabled:
        return None
    
    tts_choice = config.tts.TTS_CHOICE.upper()
    logger.info(f"æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³ç³»ç»Ÿï¼Œé€‰æ‹©: {tts_choice}")

    if tts_choice == "GPT-SOVITS":
        try:
            from voice.gpt_sovits_tts import GPTSoVITS_TTS
            tts_system = GPTSoVITS_TTS()
            if tts_system.is_enabled:
                logger.info("[TTS] âœ… GPT-SoVITS TTS åˆå§‹åŒ–æˆåŠŸ")
                return tts_system
            else:
                logger.warning("[TTS] âš ï¸ GPT-SoVITS TTS å·²é…ç½®ä½†æœªå¯ç”¨ (is_enabled: false)")
                return None
        except ImportError:
            logger.error("æ— æ³•å¯¼å…¥ GPTSoVITS_TTSï¼Œè¯·ç¡®ä¿ voice/gpt_sovits_tts.py æ–‡ä»¶å­˜åœ¨ã€‚")
            return None
        except Exception as e:
            logger.error(f"GPT-SoVITS TTS åˆå§‹åŒ–å¤±è´¥: {e}")
            return None
    elif tts_choice == "AZURE":
        # æ­¤å¤„å¯ä»¥æ·»åŠ  Azure TTS çš„åˆå§‹åŒ–é€»è¾‘
        logger.warning("Azure TTS æä¾›å•†å°šæœªå®Œå…¨å®ç°ã€‚")
        return None
    elif tts_choice == "DISABLE":
        logger.info("TTS å·²ç¦ç”¨ã€‚")
        return None
    else:
        logger.warning(f"æœªçŸ¥çš„ TTS é€‰æ‹©: {tts_choice}")
        return None

voice_system = init_voice_system()

# å·¥å…·å‡½æ•°
def now():
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return time.strftime('%H:%M:%S:') + str(int(time.time() * 1000) % 10000)

_builtin_print = print
def print(*a, **k):
    """è‡ªå®šä¹‰æ‰“å°å‡½æ•°"""
    return sys.stderr.write('[print] ' + (' '.join(map(str, a))) + '\n')

class NagaConversation: # å¯¹è¯ä¸»ç±»
    def __init__(self):
        self.mcp = get_mcp_manager()
        self.messages = []
        self.dev_mode = False
        self.api_client = None
        self.provider = config.api.provider

        # API client will be initialized on-demand in the process method
        # self._initialize_api_client()

        # åˆå§‹åŒ–MCPæœåŠ¡ç³»ç»Ÿ
        self._init_mcp_services()
        
        # åˆå§‹åŒ–GRAGè®°å¿†ç³»ç»Ÿï¼ˆåªåœ¨é¦–æ¬¡åˆå§‹åŒ–æ—¶æ˜¾ç¤ºæ—¥å¿—ï¼‰
        self.memory_manager = memory_manager
        if self.memory_manager and not SystemState._memory_initialized:
            logger.info("å¤å›­è®°å¿†ç³»ç»Ÿå·²åˆå§‹åŒ–")
            SystemState._memory_initialized = True
        
        # åˆå§‹åŒ–è¯­éŸ³å¤„ç†ç³»ç»Ÿ
        self.voice = voice_system
        if self.voice and not SystemState._voice_enabled_logged:
            logger.info(f"è¯­éŸ³åŠŸèƒ½å·²å¯ç”¨ï¼Œä½¿ç”¨ {config.tts.TTS_CHOICE} æä¾›å•†ã€‚")
            SystemState._voice_enabled_logged = True
        
        # Do not get loop in constructor, it binds to the wrong thread
        # self.loop = asyncio.get_event_loop()

    def _initialize_api_client(self):
        """æ ¹æ®é…ç½®åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        api_key = config.api.get_api_key()
        base_url = config.api.get_base_url()

        if not api_key or "placeholder" in api_key or "your-gemini-api-key-here" in api_key:
            logger.warning(f"æœªé…ç½® {self.provider} çš„APIå¯†é’¥ï¼ŒAPIåŠŸèƒ½å¯èƒ½å—é™ã€‚")
            self.api_client = None
            return

        logger.info(f"æ­£åœ¨åˆå§‹åŒ–APIå®¢æˆ·ç«¯ï¼Œæä¾›å•†: {self.provider}")

        if self.provider == "gemini":
            try:
                proxy_url = os.environ.get("HTTPS_PROXY") or os.environ.get("HTTP_PROXY")
                if proxy_url:
                    genai.configure(api_key=api_key, transport='rest', client_options={"api_endpoint": "generativelanguage.googleapis.com", "proxy": proxy_url})
                    logger.info(f"Google Gemini ä½¿ç”¨ä»£ç†: {proxy_url}")
                else:
                    genai.configure(api_key=api_key)
                
                self.api_client = genai.GenerativeModel(config.api.model)
                logger.info(f"Google Gemini æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {config.api.model}")
            except Exception as e:
                logger.error(f"Google Gemini æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
                self.api_client = None
        else: # openai, deepseekç­‰å…¼å®¹OpenAI APIçš„æä¾›å•†
            if not base_url:
                logger.error(f"{self.provider} çš„ base_url æœªé…ç½®ã€‚")
                self.api_client = None
                return
            try:
                self.api_client = AsyncOpenAI(
                    api_key=api_key, 
                    base_url=base_url.rstrip('/') + '/'
                )
                logger.info(f"{self.provider} å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {config.api.model}")
            except Exception as e:
                logger.error(f"{self.provider} å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
                self.api_client = None


    def _init_mcp_services(self):
        """åˆå§‹åŒ–MCPæœåŠ¡ç³»ç»Ÿï¼ˆåªåœ¨é¦–æ¬¡åˆå§‹åŒ–æ—¶è¾“å‡ºæ—¥å¿—ï¼Œåç»­é™é»˜ï¼‰"""
        if SystemState._mcp_services_initialized:
            # é™é»˜è·³è¿‡ï¼Œä¸è¾“å‡ºä»»ä½•æ—¥å¿—
            return
        try:
            # è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰MCPæœåŠ¡å’Œhandoff
            self.mcp.auto_register_services()
            logger.info("MCPæœåŠ¡ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            SystemState._mcp_services_initialized = True
            
            # å¼‚æ­¥å¯åŠ¨NagaPortalè‡ªåŠ¨ç™»å½•
            self._start_naga_portal_auto_login()
        except Exception as e:
            logger.error(f"MCPæœåŠ¡ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _start_naga_portal_auto_login(self):
        """å¯åŠ¨NagaPortalè‡ªåŠ¨ç™»å½•ï¼ˆå¼‚æ­¥ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦é…ç½®äº†NagaPortal
            if not config.naga_portal.username or not config.naga_portal.password:
                return  # é™é»˜è·³è¿‡ï¼Œä¸è¾“å‡ºæ—¥å¿—
            
            # åœ¨æ–°çº¿ç¨‹ä¸­å¼‚æ­¥æ‰§è¡Œç™»å½•
            def run_auto_login():
                try:
                    import sys
                    import os
                    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
                    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    sys.path.insert(0, project_root)
                    
                    from mcpserver.agent_naga_portal.portal_login_manager import auto_login_naga_portal
                    
                    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    
                    try:
                        # æ‰§è¡Œè‡ªåŠ¨ç™»å½•
                        result = loop.run_until_complete(auto_login_naga_portal())
                        
                        if result['success']:
                            # ç™»å½•æˆåŠŸï¼Œæ˜¾ç¤ºçŠ¶æ€
                            print("âœ… NagaPortalè‡ªåŠ¨ç™»å½•æˆåŠŸ")
                            self._show_naga_portal_status()
                        else:
                            # ç™»å½•å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯
                            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                            print(f"âŒ NagaPortalè‡ªåŠ¨ç™»å½•å¤±è´¥: {error_msg}")
                            self._show_naga_portal_status()
                    finally:
                        loop.close()
                        
                except Exception as e:
                    # ç™»å½•å¼‚å¸¸ï¼Œæ˜¾ç¤ºé”™è¯¯
                    print(f"âŒ NagaPortalè‡ªåŠ¨ç™»å½•å¼‚å¸¸: {e}")
                    self._show_naga_portal_status()
            
            # å¯åŠ¨åå°çº¿ç¨‹
            import threading
            login_thread = threading.Thread(target=run_auto_login, daemon=True)
            login_thread.start()
            
        except Exception as e:
            # å¯åŠ¨å¼‚å¸¸ï¼Œæ˜¾ç¤ºé”™è¯¯
            print(f"âŒ NagaPortalè‡ªåŠ¨ç™»å½•å¯åŠ¨å¤±è´¥: {e}")
            self._show_naga_portal_status()

    def _show_naga_portal_status(self):
        """æ˜¾ç¤ºNagaPortalçŠ¶æ€ï¼ˆç™»å½•å®Œæˆåè°ƒç”¨ï¼‰"""
        try:
            from mcpserver.agent_naga_portal.portal_login_manager import get_portal_login_manager
            login_manager = get_portal_login_manager()
            status = login_manager.get_status()
            cookies = login_manager.get_cookies()
            
            print(f"ğŸŒ NagaPortalçŠ¶æ€:")
            print(f"   åœ°å€: {config.naga_portal.portal_url}")
            print(f"   ç”¨æˆ·: {config.naga_portal.username[:3]}***{config.naga_portal.username[-3:] if len(config.naga_portal.username) > 6 else '***'}")
            
            if cookies:
                print(f"ğŸª Cookieä¿¡æ¯ ({len(cookies)}ä¸ª):")
                for name, value in cookies.items():
                    print(f"   {name}: {value}")
            else:
                print(f"ğŸª Cookie: æœªè·å–åˆ°")
            
            user_id = status.get('user_id')
            if user_id:
                print(f"ğŸ‘¤ ç”¨æˆ·ID: {user_id}")
            else:
                print(f"ğŸ‘¤ ç”¨æˆ·ID: æœªè·å–åˆ°")
                
            # æ˜¾ç¤ºç™»å½•çŠ¶æ€
            if status.get('is_logged_in'):
                print(f"âœ… ç™»å½•çŠ¶æ€: å·²ç™»å½•")
            else:
                print(f"âŒ ç™»å½•çŠ¶æ€: æœªç™»å½•")
                if status.get('login_error'):
                    print(f"   é”™è¯¯: {status.get('login_error')}")
                    
        except Exception as e:
            print(f"ğŸª NagaPortalçŠ¶æ€è·å–å¤±è´¥: {e}")
    
    def save_log(self, u, a):  # ä¿å­˜å¯¹è¯æ—¥å¿—
        if self.dev_mode:
            return  # å¼€å‘è€…æ¨¡å¼ä¸å†™æ—¥å¿—
        d = datetime.now().strftime('%Y-%m-%d')
        t = datetime.now().strftime('%H:%M:%S')
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = config.system.log_dir
        if not os.path.exists(log_dir):
            os.makedirs(log_dir, exist_ok=True)
            logger.info(f"å·²åˆ›å»ºæ—¥å¿—ç›®å½•: {log_dir}")
        
        # ä¿å­˜å¯¹è¯æ—¥å¿—
        log_file = os.path.join(log_dir, f"{d}.log")
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(f"[{t}] ç”¨æˆ·: {u}\n")
                f.write(f"[{t}] å¨œè¿¦: {a}\n")
                f.write("-" * 50 + "\n")
        except Exception as e:
            logger.error(f"ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")
    
    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        self.messages.append({"role": role, "content": content})
        
        # é™åˆ¶å†å²æ¶ˆæ¯æ•°é‡ï¼Œé¿å…å†…å­˜æ³„æ¼
        max_messages = 20
        if len(self.messages) > max_messages:
            self.messages = self.messages[-max_messages:]

    async def _call_llm(self, messages: List[Dict]) -> Dict:
        """è°ƒç”¨LLM API"""
        if not self.api_client:
            return {'content': 'APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’Œé…ç½®ã€‚', 'status': 'error'}

        try:
            if self.provider == "gemini":
                # å°†æ¶ˆæ¯è½¬æ¢ä¸ºGeminiæ ¼å¼
                # Geminiæ²¡æœ‰ä¸¥æ ¼çš„system roleï¼Œæˆ‘ä»¬å°†system promptåˆå¹¶åˆ°ç¬¬ä¸€ä¸ªuser messageä¸­
                system_prompt = next((m['content'] for m in messages if m['role'] == 'system'), "")
                
                gemini_messages = []
                is_first_user_message = True
                for m in messages:
                    if m['role'] == 'user':
                        if is_first_user_message and system_prompt:
                            gemini_messages.append({'role': 'user', 'parts': [system_prompt + "\n\n" + m['content']]})
                            is_first_user_message = False
                        else:
                            gemini_messages.append({'role': 'user', 'parts': [m['content']]})
                    elif m['role'] == 'assistant':
                        # Gemini API éœ€è¦äº¤æ›¿çš„ç”¨æˆ·å’Œæ¨¡å‹è§’è‰²
                        if gemini_messages and gemini_messages[-1]['role'] == 'model':
                            # å¦‚æœä¸Šä¸€æ¡ä¹Ÿæ˜¯modelï¼Œåˆ™åˆå¹¶å†…å®¹
                             gemini_messages[-1]['parts'][0] += "\n" + m['content']
                        else:
                            gemini_messages.append({'role': 'model', 'parts': [m['content']]})

                # ç¡®ä¿ç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯ user
                if not gemini_messages or gemini_messages[0]['role'] != 'user':
                     gemini_messages.insert(0, {'role': 'user', 'parts': [system_prompt or "ä½ å¥½"]})


                resp = await self.api_client.generate_content_async(gemini_messages)
                return {
                    'content': resp.text,
                    'status': 'success'
                }
            else: # DeepSeek, OpenAI
                resp = await self.api_client.chat.completions.create(
                    model=config.api.model, 
                    messages=messages, 
                    temperature=config.api.temperature, 
                    max_tokens=config.api.max_tokens, 
                    stream=False
                )
                return {
                    'content': resp.choices[0].message.content,
                    'status': 'success'
                }
        except Exception as e:
            logger.error(f"{self.provider} APIè°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯å¤±è´¥
            if "API key" in str(e) or "authentication" in str(e).lower():
                 error_message = f"APIè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä½ çš„ {self.provider} APIå¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚"
            else:
                error_message = f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
            return {
                'content': error_message,
                'status': 'error'
            }

    # å·¥å…·è°ƒç”¨å¾ªç¯ç›¸å…³æ–¹æ³•
    def handle_llm_response(self, a, mcp):
        # åªä¿ç•™æ™®é€šæ–‡æœ¬æµå¼è¾“å‡ºé€»è¾‘ #
        async def text_stream():
            for line in a.splitlines():
                yield ("å¨œè¿¦", line)
        return text_stream()

    def _format_services_for_prompt(self, available_services: dict) -> str:
        """æ ¼å¼åŒ–å¯ç”¨æœåŠ¡åˆ—è¡¨ä¸ºpromptå­—ç¬¦ä¸²ï¼ŒMCPæœåŠ¡å’ŒAgentæœåŠ¡åˆ†å¼€ï¼ŒåŒ…å«å…·ä½“è°ƒç”¨æ ¼å¼"""
        mcp_services = available_services.get("mcp_services", [])
        agent_services = available_services.get("agent_services", [])
        
        # è·å–æœ¬åœ°åŸå¸‚ä¿¡æ¯å’Œå½“å‰æ—¶é—´
        local_city = "æœªçŸ¥åŸå¸‚"
        current_time = ""
        try:
            # ä»WeatherTimeAgentè·å–æœ¬åœ°åŸå¸‚ä¿¡æ¯
            from mcpserver.agent_weather_time.agent_weather_time import WeatherTimeTool
            weather_tool = WeatherTimeTool()
            local_city = getattr(weather_tool, '_local_city', 'æœªçŸ¥åŸå¸‚') or 'æœªçŸ¥åŸå¸‚'
            
            # è·å–å½“å‰æ—¶é—´
            from datetime import datetime
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        except Exception as e:
            print(f"[DEBUG] è·å–æœ¬åœ°ä¿¡æ¯å¤±è´¥: {e}")
        
        # æ ¼å¼åŒ–MCPæœåŠ¡åˆ—è¡¨ï¼ŒåŒ…å«å…·ä½“è°ƒç”¨æ ¼å¼
        mcp_list = []
        for service in mcp_services:
            name = service.get("name", "")
            description = service.get("description", "")
            display_name = service.get("display_name", name)
            tools = service.get("available_tools", [])
            
            # å±•ç¤ºname+displayName
            if description:
                mcp_list.append(f"- {name}: {description}")
            else:
                mcp_list.append(f"- {name}")
            
            # ä¸ºæ¯ä¸ªå·¥å…·æ˜¾ç¤ºå…·ä½“è°ƒç”¨æ ¼å¼
            if tools:
                for tool in tools:
                    tool_name = tool.get('name', '')
                    tool_desc = tool.get('description', '')
                    tool_example = tool.get('example', '')
                    
                    if tool_name and tool_example:
                        # è§£æç¤ºä¾‹JSONï¼Œæå–å‚æ•°
                        try:
                            import json
                            example_data = json.loads(tool_example)
                            params = []
                            for key, value in example_data.items():
                                if key != 'tool_name':
                                    # ç‰¹æ®Šå¤„ç†cityå‚æ•°ï¼Œæ³¨å…¥æœ¬åœ°åŸå¸‚ä¿¡æ¯
                                    if key == 'city' and name == 'WeatherTimeAgent':
                                        params.append(f"{key}: {local_city}")
                                    else:
                                        params.append(f"{key}: {value}")
                            
                            # æ„å»ºè°ƒç”¨æ ¼å¼
                            format_str = f"  {tool_name}: ï½›\n"
                            format_str += f"    \"agentType\": \"mcp\",\n"
                            format_str += f"    \"service_name\": \"{name}\",\n"
                            format_str += f"    \"tool_name\": \"{tool_name}\",\n"
                            for param in params:
                                # å°†ä¸­æ–‡å‚æ•°åè½¬æ¢ä¸ºè‹±æ–‡
                                param_key, param_value = param.split(': ', 1)
                                if param_key == 'city' and name == 'WeatherTimeAgent':
                                    format_str += f"    \"{param_key}\": \"{local_city}\",\n"
                                else:
                                    format_str += f"    \"{param_key}\": \"{param_value}\",\n"
                            format_str += f"  ï½\n"
                            
                            mcp_list.append(format_str)
                        except:
                            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
                            mcp_list.append(f"  {tool_name}: ä½¿ç”¨tool_nameå‚æ•°è°ƒç”¨")
        
        # æ ¼å¼åŒ–AgentæœåŠ¡åˆ—è¡¨
        agent_list = []
        
        # 1. æ·»åŠ handoffæœåŠ¡
        for service in agent_services:
            name = service.get("name", "")
            description = service.get("description", "")
            tool_name = service.get("tool_name", "agent")
            display_name = service.get("display_name", name)
            # å±•ç¤ºname+displayName
            if description:
                agent_list.append(f"- {name}(å·¥å…·å: {tool_name}): {description}")
            else:
                agent_list.append(f"- {name}(å·¥å…·å: {tool_name})")
        
        # 2. ç›´æ¥ä»AgentManagerè·å–å·²æ³¨å†Œçš„Agent
        try:
            from mcpserver.agent_manager import get_agent_manager
            agent_manager = get_agent_manager()
            agent_manager_agents = agent_manager.get_available_agents()
            
            for agent in agent_manager_agents:
                name = agent.get("name", "")
                base_name = agent.get("base_name", "")
                description = agent.get("description", "")
                
                # å±•ç¤ºæ ¼å¼ï¼šbase_name: æè¿°
                if description:
                    agent_list.append(f"- {base_name}: {description}")
                else:
                    agent_list.append(f"- {base_name}")
                    
        except Exception as e:
            # å¦‚æœAgentManagerä¸å¯ç”¨ï¼Œé™é»˜å¤„ç†
            pass
        
        # æ·»åŠ æœ¬åœ°ä¿¡æ¯è¯´æ˜
        local_info = f"\n\nã€å½“å‰ç¯å¢ƒä¿¡æ¯ã€‘\n- æœ¬åœ°åŸå¸‚: {local_city}\n- å½“å‰æ—¶é—´: {current_time}\n\nã€ä½¿ç”¨è¯´æ˜ã€‘\n- å¤©æ°”/æ—¶é—´æŸ¥è¯¢æ—¶ï¼Œè¯·ä½¿ç”¨ä¸Šè¿°æœ¬åœ°åŸå¸‚ä¿¡æ¯ä½œä¸ºcityå‚æ•°\n- æ‰€æœ‰æ—¶é—´ç›¸å…³æŸ¥è¯¢éƒ½åŸºäºå½“å‰ç³»ç»Ÿæ—¶é—´"
        
        # è¿”å›æ ¼å¼åŒ–çš„æœåŠ¡åˆ—è¡¨
        result = {
            "available_mcp_services": "\n".join(mcp_list) + local_info if mcp_list else "æ— " + local_info,
            "available_agent_services": "\n".join(agent_list) if agent_list else "æ— "
        }
        
        return result

    async def process(self, u, is_voice_input=False):  # æ·»åŠ is_voice_inputå‚æ•°
        try:
            # å§‹ç»ˆåœ¨å¤„ç†å¼€å§‹æ—¶åˆå§‹åŒ–/é‡æ–°åˆå§‹åŒ–APIå®¢æˆ·ç«¯
            # è¿™å¯ä»¥ç¡®ä¿å®¢æˆ·ç«¯ä½¿ç”¨å½“å‰å·¥ä½œçº¿ç¨‹çš„äº‹ä»¶å¾ªç¯
            self._initialize_api_client()

            # å¼€å‘è€…æ¨¡å¼ä¼˜å…ˆåˆ¤æ–­
            if u.strip().lower() == "#devmode":
                self.dev_mode = not self.dev_mode  # åˆ‡æ¢æ¨¡å¼
                status = "è¿›å…¥" if self.dev_mode else "é€€å‡º"
                yield ("å¨œè¿¦", f"å·²{status}å¼€å‘è€…æ¨¡å¼")
                return

            # åªåœ¨è¯­éŸ³è¾“å…¥æ—¶æ˜¾ç¤ºå¤„ç†æç¤º
            if is_voice_input:
                print(f"å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥ï¼š{now()}")  # è¯­éŸ³è½¬æ–‡æœ¬ç»“æŸï¼Œå¼€å§‹å¤„ç†
                     
            # æ·»åŠ handoffæç¤ºè¯
            system_prompt = f"{RECOMMENDED_PROMPT_PREFIX}\n{config.prompts.naga_system_prompt}"
            
            # è·å–è¿‡æ»¤åçš„æœåŠ¡åˆ—è¡¨
            available_services = self.mcp.get_available_services_filtered()
            services_text = self._format_services_for_prompt(available_services)
            
            # ç®€åŒ–çš„æ¶ˆæ¯æ‹¼æ¥é€»è¾‘ï¼ˆUIç•Œé¢ä½¿ç”¨ï¼‰
            sysmsg = {"role": "system", "content": system_prompt.format(**services_text)}
            msgs = [sysmsg] if sysmsg else []
            msgs += self.messages[-20:] + [{"role": "user", "content": u}]

            print(f"GTPè¯·æ±‚å‘é€ï¼š{now()}")  # AIè¯·æ±‚å‰
            
            # ç¦ç”¨éçº¿æ€§æ€è€ƒåˆ¤æ–­
            # thinking_task = None
            # if hasattr(self, 'tree_thinking') and self.tree_thinking and getattr(self.tree_thinking, 'is_enabled', False):
            #     # å¯åŠ¨å¼‚æ­¥æ€è€ƒåˆ¤æ–­ä»»åŠ¡
            #     import asyncio
            #     thinking_task = asyncio.create_task(self._async_thinking_judgment(u))
            
            # æ™®é€šæ¨¡å¼ï¼šèµ°å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆæ ¹æ®é…ç½®å†³å®šæ˜¯å¦æµå¼ï¼‰
            try:
                # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨æµå¼å¤„ç†
                is_streaming = config.system.stream_mode
                result = await tool_call_loop(msgs, self.mcp, self._call_llm, is_streaming=is_streaming)
                final_content = result['content']
                recursion_depth = result['recursion_depth']
                
                if recursion_depth > 0:
                    print(f"å·¥å…·è°ƒç”¨å¾ªç¯å®Œæˆï¼Œå…±æ‰§è¡Œ {recursion_depth} è½®")
                
                # æ ¹æ®é…ç½®å†³å®šè¾“å‡ºæ–¹å¼
                if is_streaming:
                    # æµå¼è¾“å‡ºæœ€ç»ˆç»“æœ
                    for line in final_content.splitlines():
                        yield ("å¨œè¿¦", line)
                else:
                    # éæµå¼è¾“å‡ºå®Œæ•´ç»“æœ
                    yield ("å¨œè¿¦", final_content)
                
                # ä¿å­˜å¯¹è¯å†å²
                self.messages += [{"role": "user", "content": u}, {"role": "assistant", "content": final_content}]
                self.save_log(u, final_content)
                
                # GRAGè®°å¿†å­˜å‚¨ï¼ˆå¼€å‘è€…æ¨¡å¼ä¸å†™å…¥ï¼‰
                if self.memory_manager and not self.dev_mode:
                    try:
                        await self.memory_manager.add_conversation_memory(u, final_content)
                    except Exception as e:
                        logger.error(f"GRAGè®°å¿†å­˜å‚¨å¤±è´¥: {e}")
                
                # ç¦ç”¨å¼‚æ­¥æ€è€ƒåˆ¤æ–­ç»“æœæ£€æŸ¥
                # if thinking_task and not thinking_task.done():
                #     # ç­‰å¾…æ€è€ƒåˆ¤æ–­å®Œæˆï¼ˆæœ€å¤šç­‰å¾…3ç§’ï¼‰
                #     try:
                #         await asyncio.wait_for(thinking_task, timeout=3.0)
                #         if thinking_task.result():
                #             yield ("å¨œè¿¦", "\nğŸ’¡ è¿™ä¸ªé—®é¢˜è¾ƒä¸ºå¤æ‚ï¼Œä¸‹é¢æˆ‘ä¼šæ›´è¯¦ç»†åœ°è§£é‡Šè¿™ä¸ªæµç¨‹...")
                #             # å¯åŠ¨æ·±åº¦æ€è€ƒ
                #             try:
                #                 thinking_result = await self.tree_thinking.think_deeply(u)
                #                 if thinking_result and "answer" in thinking_result:
                #                     # ç›´æ¥ä½¿ç”¨thinkingç³»ç»Ÿçš„ç»“æœï¼Œé¿å…é‡å¤å¤„ç†
                #                     yield ("å¨œè¿¦", f"\n{thinking_result['answer']}")
                #                     
                #                     # æ›´æ–°å¯¹è¯å†å²
                #                     final_thinking_answer = thinking_result['answer']
                #                     self.messages[-1] = {"role": "assistant", "content": final_content + "\n\n" + final_thinking_answer}
                #                     self.save_log(u, final_content + "\n\n" + final_thinking_answer)
                #                     
                #                     # GRAGè®°å¿†å­˜å‚¨ï¼ˆå¼€å‘è€…æ¨¡å¼ä¸å†™å…¥ï¼‰
                #                     if self.memory_manager and not self.dev_mode:
                #                         try:
                #                             await self.memory_manager.add_conversation_memory(u, final_content + "\n\n" + final_thinking_answer)
                #                         except Exception as e:
                #                             logger.error(f"GRAGè®°å¿†å­˜å‚¨å¤±è´¥: {e}")
                #             except Exception as e:
                #                 logger.error(f"æ·±åº¦æ€è€ƒå¤„ç†å¤±è´¥: {e}")
                #                 yield ("å¨œè¿¦", f"ğŸŒ³ æ·±åº¦æ€è€ƒç³»ç»Ÿå‡ºé”™: {str(e)}")
                #     except asyncio.TimeoutError:
                #         # è¶…æ—¶å–æ¶ˆä»»åŠ¡
                #         thinking_task.cancel()
                #     except Exception as e:
                #         logger.debug(f"æ€è€ƒåˆ¤æ–­ä»»åŠ¡å¼‚å¸¸: {e}")
                
            except Exception as e:
                print(f"å·¥å…·è°ƒç”¨å¾ªç¯å¤±è´¥: {e}")
                yield ("å¨œè¿¦", f"[MCPå¼‚å¸¸]: {e}")
                return

            return
        except Exception as e:
            import sys
            import traceback
            traceback.print_exc(file=sys.stderr)
            yield ("å¨œè¿¦", f"[MCPå¼‚å¸¸]: {e}")
            return

    async def get_response(self, prompt: str, temperature: float = 0.7) -> str:
        """ä¸ºæ ‘çŠ¶æ€è€ƒç³»ç»Ÿç­‰æä¾›APIè°ƒç”¨æ¥å£""" # ç»Ÿä¸€æ¥å£
        try:
            response = await self.async_client.chat.completions.create(
                model=config.api.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=config.api.max_tokens
            )
            return response.choices[0].message.content
        except RuntimeError as e:
            if "handler is closed" in str(e):
                logger.debug(f"å¿½ç•¥è¿æ¥å…³é—­å¼‚å¸¸ï¼Œé‡æ–°åˆ›å»ºå®¢æˆ·ç«¯: {e}")
                # é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯å¹¶é‡è¯•
                self.async_client = AsyncOpenAI(api_key=config.api.api_key, base_url=config.api.base_url.rstrip('/') + '/')
                response = await self.async_client.chat.completions.create(
                    model=config.api.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=temperature,
                    max_tokens=config.api.max_tokens
                )
                return response.choices[0].message.content
            else:
                logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
                return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"
        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
            return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"

    # async def _async_thinking_judgment(self, question: str) -> bool:
    #     """å¼‚æ­¥åˆ¤æ–­é—®é¢˜æ˜¯å¦éœ€è¦æ·±åº¦æ€è€ƒ
        
    #     Args:
    #         question: ç”¨æˆ·é—®é¢˜
            
    #     Returns:
    #         bool: æ˜¯å¦éœ€è¦æ·±åº¦æ€è€ƒ
    #     """
    #     try:
    #         if not self.tree_thinking:
    #             return False
            
    #         # ä½¿ç”¨thinkingæ–‡ä»¶å¤¹ä¸­ç°æˆçš„éš¾åº¦åˆ¤æ–­å™¨
    #         difficulty_assessment = await self.tree_thinking.difficulty_judge.assess_difficulty(question)
    #         difficulty = difficulty_assessment.get("difficulty", 3)
            
    #         # æ ¹æ®éš¾åº¦åˆ¤æ–­æ˜¯å¦éœ€è¦æ·±åº¦æ€è€ƒ
    #         # éš¾åº¦4-5ï¼ˆå¤æ‚/æéš¾ï¼‰å»ºè®®æ·±åº¦æ€è€ƒ
    #         should_think_deeply = difficulty >= 4
            
    #         logger.info(f"éš¾åº¦åˆ¤æ–­ï¼š{difficulty}/5ï¼Œå»ºè®®æ·±åº¦æ€è€ƒï¼š{should_think_deeply}")
    #         return should_think_deeply
                   
    #     except Exception as e:
    #         logger.debug(f"å¼‚æ­¥æ€è€ƒåˆ¤æ–­å¤±è´¥: {e}")
    #         return False

async def process_user_message(s,msg):
    # å½“å¯ç”¨è¯­éŸ³ç³»ç»Ÿä¸”æ— æ–‡æœ¬è¾“å…¥æ—¶ï¼Œå¯åŠ¨è¯­éŸ³è¯†åˆ«
    if config.system.voice_enabled and not msg: 
        # å½“s.voiceä¸ä¸ºNoneæ—¶ï¼ˆå³è¯­éŸ³ç³»ç»Ÿæ­£å¸¸åˆå§‹åŒ–ï¼‰æ‰è¿›è¡Œè¯­éŸ³è¯†åˆ«
        if s.voice:
            async for text in s.voice.stt_stream():
                if text:
                    msg=text
                    break
            return await s.process(msg, is_voice_input=True)  # è¯­éŸ³è¾“å…¥
    return await s.process(msg, is_voice_input=False)  # æ–‡å­—è¾“å…¥
